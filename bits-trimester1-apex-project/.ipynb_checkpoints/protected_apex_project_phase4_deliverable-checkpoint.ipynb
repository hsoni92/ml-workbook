{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bHD3MHS4mFKK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: /Users/himanshu.soni/hsoni92-git/ml-workbook/bits-trimester1-apex-project/.venv/bin/pip: bad interpreter: /Users/himanshu.soni/hsoni92-git/ml-workbook/bits-trimester1-apex-project/venv/bin/python3.13: no such file or directory\n",
            "/Users/himanshu.soni/.pyenv/pyenv.d/exec/pip-rehash/pip: /Users/himanshu.soni/hsoni92-git/ml-workbook/bits-trimester1-apex-project/.venv/bin/pip: /Users/himanshu.soni/hsoni92-git/ml-workbook/bits-trimester1-apex-project/venv: bad interpreter: No such file or directory\n",
            "zsh:1: unknown file attribute: b\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install Kaggle API\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Step 2: Create kaggle.json with your credentials\n",
        "import json\n",
        "import os\n",
        "\n",
        "kaggle_token = {\n",
        "    \"username\": \"himanshusoni001\",\n",
        "    \"key\": \"7888d0ba07df9b4b51271fe3c97fac80\"\n",
        "}\n",
        "\n",
        "basepath = \".\"\n",
        "# Write the token to the correct location\n",
        "os.makedirs(basepath, exist_ok=True)\n",
        "with open(os.path.join(basepath, 'kaggle.json'), 'w') as f:\n",
        "    json.dump(kaggle_token, f)\n",
        "\n",
        "# Set permission\n",
        "!chmod 600 os.path.join(basepath, 'kaggle.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4lLmeVxHC9z",
        "outputId": "e87605aa-7603-4823-e5e9-21a109c513e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: /Users/himanshu.soni/hsoni92-git/ml-workbook/bits-trimester1-apex-project/.venv/bin/kaggle: bad interpreter: /Users/himanshu.soni/hsoni92-git/ml-workbook/bits-trimester1-apex-project/venv/bin/python3.13: no such file or directory\n",
            "unzip:  cannot find or open house-prices-advanced-regression-techniques.zip, house-prices-advanced-regression-techniques.zip.zip or house-prices-advanced-regression-techniques.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Download dataset using Kaggle API\n",
        "!kaggle competitions download -c house-prices-advanced-regression-techniques\n",
        "\n",
        "# Step 4: Unzip the downloaded dataset\n",
        "!unzip -o house-prices-advanced-regression-techniques.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "OZNLlRPBm6zF",
        "outputId": "3a85f12a-6c8c-49e2-8c73-bfb5db8916f7"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Optional: Preview data\u001b[39;00m\n\u001b[32m     10\u001b[39m data.head()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/hsoni92-git/ml-workbook/bits-trimester1-apex-project/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/hsoni92-git/ml-workbook/bits-trimester1-apex-project/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/hsoni92-git/ml-workbook/bits-trimester1-apex-project/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/hsoni92-git/ml-workbook/bits-trimester1-apex-project/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/hsoni92-git/ml-workbook/bits-trimester1-apex-project/.venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ],
      "source": [
        "# Step 5: Load and use the dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data = pd.read_csv('train.csv')\n",
        "\n",
        "# Optional: Preview data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "n4_nFF6krIRM",
        "outputId": "753474d8-91c8-4180-adc7-132113e9c0c6"
      },
      "outputs": [],
      "source": [
        "data.tail(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c69nsIfoZJN4"
      },
      "source": [
        "#                    **DATA AUDIT AND AVAILABILITY CHECK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OQTWWhVZdwj",
        "outputId": "33b802fe-e2ec-4c5e-e28a-8ee6b2285794"
      },
      "outputs": [],
      "source": [
        "# 1. Shape of the dataset\n",
        "print(\"\\nShape of dataset:\", data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FavRAeEIaJU-",
        "outputId": "7d24d9b6-7d66-4237-fc71-0a320288f982"
      },
      "outputs": [],
      "source": [
        "# 2. Data types of each column\n",
        "print(\"\\nData types of each column:\")\n",
        "print(data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eroc6QJ4aNNH",
        "outputId": "ca96faff-0476-438f-f333-bac7d4ffe73f"
      },
      "outputs": [],
      "source": [
        "# 3. Missing values per column\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BIEX1pdaXgE",
        "outputId": "52a989f5-e97a-4656-b47e-124987d5d1c4"
      },
      "outputs": [],
      "source": [
        "# 4. Data Information\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chwHpa9Qahr9",
        "outputId": "50362298-76fa-4a00-ce79-59907444ca2b"
      },
      "outputs": [],
      "source": [
        "# 5. Check for negative or invalid values\n",
        "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(numeric_cols)\n",
        "print(\"\\nNegative values:\")\n",
        "for col in numeric_cols:\n",
        "    if (data[col] < 0).any():\n",
        "        print(f\"\\033[91mColumn '{col}' has negative values.\\033[0m\")\n",
        "        print(data[data[col] < 0][[col]])\n",
        "    else:\n",
        "        print(f\"\\033[92mColumn '{col}' has no negative values.\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5reXiGh1bG2w",
        "outputId": "e68758e8-e917-4046-97f3-42b5ebacf5f3"
      },
      "outputs": [],
      "source": [
        "# 6. Duplicate rows\n",
        "print(\"\\nNumber of duplicate rows:\", data.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2b4khmYbmD6"
      },
      "source": [
        "# **EXPLORATORY DATA ANALYSIS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmhYWmupbYbc",
        "outputId": "777c6ef8-c04c-4fc6-b83e-cd2081515286"
      },
      "outputs": [],
      "source": [
        "#Summary statistics for numeric columns\n",
        "print(\"\\nSummary statistics:\")\n",
        "print(data.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHiMF75Ybt0F",
        "outputId": "b3a941a4-ee80-43b7-f452-f8e4c4c95d88"
      },
      "outputs": [],
      "source": [
        "#Summary statistics for categorical columns\n",
        "for col in data.columns:\n",
        "    if (data[col].dtype=='object'):\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(data[col].value_counts())\n",
        "    else:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfZxRyf4cfGg",
        "outputId": "260d3bea-98d0-4f54-99ba-0a1969ae3566"
      },
      "outputs": [],
      "source": [
        "# Calculate average property prices across neighborhoods\n",
        "average_price_by_neighborhood = data.groupby('Neighborhood')['SalePrice'].mean().sort_values()\n",
        "\n",
        "# Identify the most affordable neighborhoods\n",
        "affordable_neighborhoods = average_price_by_neighborhood.head(5)\n",
        "\n",
        "# Identify the most expensive neighborhoods\n",
        "expensive_neighborhoods = average_price_by_neighborhood.tail(5)\n",
        "\n",
        "# Average property size and price by building type\n",
        "average_size_and_price = data.groupby('BldgType')[['GrLivArea', 'SalePrice']].mean()\n",
        "\n",
        "# Average price by overall quality\n",
        "average_price_by_quality = data.groupby('OverallQual')['SalePrice'].mean().sort_values()\n",
        "\n",
        "print(\"Average Price by Neighborhood:\")\n",
        "print(average_price_by_neighborhood)\n",
        "\n",
        "print(\"\\nMost Affordable Neighborhoods:\")\n",
        "print(affordable_neighborhoods)\n",
        "\n",
        "print(\"\\nMost Expensive Neighborhoods:\")\n",
        "print(expensive_neighborhoods)\n",
        "\n",
        "print(\"\\nAverage Living Area and Price by Building Type:\")\n",
        "print(average_size_and_price)\n",
        "\n",
        "print(\"\\nAverage Price by Overall Quality:\")\n",
        "print(average_price_by_quality)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XjiMMqvEev_Q",
        "outputId": "61b147f9-69c6-4ca3-cba1-da246570b66d"
      },
      "outputs": [],
      "source": [
        "# UNIVARIATE VISUALISATION\n",
        "for col in numeric_cols:\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.histplot(data[col], kde=True, bins=20, color='skyblue')\n",
        "    plt.title(f'Histogram & KDE of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DH34o1HUfrWg",
        "outputId": "0ba77d16-dc36-4c14-96ea-814f9256657d"
      },
      "outputs": [],
      "source": [
        "# Correlation heat map\n",
        "numeric_data = data.select_dtypes(include=[np.number])\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(numeric_data.corr(), annot=False, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# --- Correlation Matrix With target---\n",
        "num_cols = numeric_data.columns\n",
        "target = 'SalePrice'\n",
        "corr = data[num_cols].corr()\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr[target].sort_values(ascending=False).to_frame(),\n",
        "            annot=True, cmap='coolwarm', fmt=\".2f\", cbar=False)\n",
        "plt.title(\"Correlation of Features with SalePrice\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "J0mWAugPjNLa",
        "outputId": "346411e4-aa99-4e46-fa3a-8c5412d883d8"
      },
      "outputs": [],
      "source": [
        "# --- Target Distribution (SalePrice) ---\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(data[target], kde=True, bins=40, color='teal')\n",
        "plt.title(\"SalePrice Distribution (Before Log Transform)\")\n",
        "plt.xlabel(\"SalePrice\")\n",
        "plt.show()\n",
        "\n",
        "# Check skewness and log-transform if needed\n",
        "skew_val = data[target].skew()\n",
        "print(f\"Skewness of {target}: {skew_val:.2f}\")\n",
        "if skew_val > 0.75:\n",
        "    data['SalePrice_log'] = np.log1p(data[target])\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.histplot(data['SalePrice_log'], kde=True, bins=40, color='orange')\n",
        "    plt.title(\"SalePrice Distribution (After Log Transform)\")\n",
        "    plt.xlabel(\"Log(SalePrice)\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "lW39EPRbhGDn",
        "outputId": "56201b42-1eea-46d9-8474-1030383a737c"
      },
      "outputs": [],
      "source": [
        "#BIVARIATE VISUALISATION\n",
        "\n",
        "# Average price by Neighborhood\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Compute mean sale price per neighborhood and sort\n",
        "sorted_data = data.groupby('Neighborhood')['SalePrice'].mean().sort_values().reset_index()\n",
        "\n",
        "# Use sorted data in the plot\n",
        "sns.pointplot(x='Neighborhood', y='SalePrice', data=sorted_data, errorbar=None)\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Average Sale Price by Neighborhood')\n",
        "plt.ylabel('Sale Price')\n",
        "plt.xlabel('Neighborhood')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "LifmTDFMhXzp",
        "outputId": "c113acc0-137f-4dfb-e713-a90d75276aa4"
      },
      "outputs": [],
      "source": [
        "# Average price by Overall Quality\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.pointplot(x=data['OverallQual'], y=data['SalePrice'], errorbar=None)\n",
        "plt.title('Average Sale Price by Overall Quality')\n",
        "plt.ylabel('Sale Price')\n",
        "plt.xlabel('Overall Quality')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "-bq_WUqahhHQ",
        "outputId": "ae21e4d5-b82f-4845-ed2b-a020b5ebee5e"
      },
      "outputs": [],
      "source": [
        "# Average price by Building Type\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.pointplot(x=data['BldgType'], y=data['SalePrice'], errorbar=None)\n",
        "plt.title('Average Sale Price by Building Type')\n",
        "plt.ylabel('Sale Price')\n",
        "plt.xlabel('Building Type')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-YV8Cu1iGiC"
      },
      "source": [
        "# **DATA CLEANING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "OFcy9HoziKo2",
        "outputId": "5d6c25d8-915d-49f2-f739-d149b66a8d5a"
      },
      "outputs": [],
      "source": [
        "# Handle missing values\n",
        "# First, let's identify columns with high missing percentages (>50%)\n",
        "missing_pct = (data.isnull().sum() / len(data)) * 100\n",
        "high_missing = missing_pct[missing_pct > 50].index.tolist()\n",
        "print(f\"Columns with >50% missing values: {high_missing}\")\n",
        "\n",
        "# Drop columns with high missing percentages and the Id column\n",
        "columns_to_drop = ['Id'] + high_missing\n",
        "datan = data.drop(columns=columns_to_drop, errors='ignore').copy()\n",
        "\n",
        "# Handle missing values in remaining columns\n",
        "# For numerical columns: impute with median\n",
        "numeric_cols_with_missing = datan.select_dtypes(include=[np.number]).columns[datan.select_dtypes(include=[np.number]).isnull().any()].tolist()\n",
        "for col in numeric_cols_with_missing:\n",
        "    datan.loc[:, col] = datan[col].fillna(datan[col].median())\n",
        "\n",
        "# For categorical columns: impute with mode or 'None' for meaningful features\n",
        "categorical_cols_with_missing = datan.select_dtypes(include=['object']).columns[datan.select_dtypes(include=['object']).isnull().any()].tolist()\n",
        "for col in categorical_cols_with_missing:\n",
        "    # For features where 'None' is meaningful (e.g., no garage, no basement)\n",
        "    if col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
        "               'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
        "               'FireplaceQu', 'Fence', 'MiscFeature']:\n",
        "        datan.loc[:, col] = datan[col].fillna('None')\n",
        "    else:\n",
        "        datan.loc[:, col] = datan[col].fillna(datan[col].mode()[0])\n",
        "\n",
        "print(f\"\\nShape after cleaning: {datan.shape}\")\n",
        "print(f\"Remaining missing values: {datan.isnull().sum().sum()}\")\n",
        "datan.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AdWwembIj1B4",
        "outputId": "3488b6dc-ded0-4cad-9dcf-a9edab856776"
      },
      "outputs": [],
      "source": [
        "# OUTLIER DETECTION\n",
        "numeric_col = datan.select_dtypes(include=['int64', 'float64']).columns\n",
        "outlier_indices = {}\n",
        "\n",
        "for col in numeric_col:\n",
        "    Q1 = datan[col].quantile(0.25)\n",
        "    Q3 = datan[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Identify outliers\n",
        "    outliers = datan[(datan[col] < lower_bound) | (datan[col] > upper_bound)]\n",
        "    outlier_indices[col] = outliers.index.tolist()\n",
        "\n",
        "    if len(outliers) > 0:\n",
        "        print(f\"{col}: {len(outliers)} outliers\")\n",
        "\n",
        "print(f\"\\nTotal columns checked: {len(numeric_col)}\")\n",
        "\n",
        "# --- Outlier Inspection ---\n",
        "top_corr = corr[target].abs().sort_values(ascending=False).head(6).index\n",
        "sns.pairplot(data[top_corr], diag_kind=\"kde\")\n",
        "plt.suptitle(\"Pairplot of Top Features vs SalePrice\", y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Xxh9Fav2c6",
        "outputId": "af3db8e7-0243-400d-f7fb-b358384cb2d8"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# ðŸ§® Outlier Capping / Winsorization\n",
        "# ==========================================\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# Identify numeric columns\n",
        "numeric_cols = datan.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Apply Winsorization (limit at 1stâ€“99th percentile)\n",
        "for col in numeric_cols:\n",
        "    lower, upper = datan[col].quantile([0.01, 0.99])\n",
        "    datan[col] = np.clip(datan[col], lower, upper)\n",
        "\n",
        "print(\"âœ… Outliers capped at 1stâ€“99th percentile for numeric columns.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gevmF6D9l-I5"
      },
      "source": [
        "# Note: Outliers found but not removing them as they may be legitimate high-value properties\n",
        "# For house price prediction, extreme values can be real luxury homes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_R-q5X7jFkE"
      },
      "source": [
        "# **FEATURE ENGINEERING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jOfajkyMjEC6",
        "outputId": "dffeb77f-360a-4b90-c14f-1eb91f14d144"
      },
      "outputs": [],
      "source": [
        "# CREATE NEW FEATURES FROM EXISTING COLUMNS\n",
        "\n",
        "# 1. Total Square Footage\n",
        "datan['TotalSF'] = datan['TotalBsmtSF'] + datan['1stFlrSF'] + datan['2ndFlrSF']\n",
        "\n",
        "# 2. Property Age (from year sold)\n",
        "datan['PropertyAge'] = datan['YrSold'] - datan['YearBuilt']\n",
        "\n",
        "# 3. Years Since Remodel\n",
        "datan['RemodAge'] = datan['YrSold'] - datan['YearRemodAdd']\n",
        "\n",
        "# 4. Binary features - Has Garage\n",
        "datan['HasGarage'] = (datan['GarageArea'] > 0).astype(int)\n",
        "\n",
        "# 5. Binary features - Has Basement\n",
        "datan['HasBasement'] = (datan['TotalBsmtSF'] > 0).astype(int)\n",
        "\n",
        "# 6. Binary features - Has Fireplace\n",
        "datan['HasFireplace'] = (datan['Fireplaces'] > 0).astype(int)\n",
        "\n",
        "# 7. Binary features - Has 2nd Floor\n",
        "datan['Has2ndFloor'] = (datan['2ndFlrSF'] > 0).astype(int)\n",
        "\n",
        "# 8. Quality Score (interaction feature)\n",
        "datan['QualityScore'] = datan['OverallQual'] * datan['OverallCond']\n",
        "\n",
        "# 9. Total Bathrooms\n",
        "datan['TotalBath'] = datan['FullBath'] + 0.5 * datan['HalfBath'] + datan['BsmtFullBath'] + 0.5 * datan['BsmtHalfBath']\n",
        "\n",
        "# 10. Total Porch Area\n",
        "datan['TotalPorchSF'] = datan['OpenPorchSF'] + datan['EnclosedPorch'] + datan['3SsnPorch'] + datan['ScreenPorch']\n",
        "\n",
        "print(\"New features created:\")\n",
        "print(\"TotalSF, PropertyAge, RemodAge, HasGarage, HasBasement, HasFireplace,\")\n",
        "print(\"Has2ndFloor, QualityScore, TotalBath, TotalPorchSF\")\n",
        "print(f\"\\nUpdated shape: {datan.shape}\")\n",
        "datan[['TotalSF', 'PropertyAge', 'RemodAge', 'HasGarage', 'HasBasement', 'QualityScore', 'TotalBath']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "uBHMerLrm3tj",
        "outputId": "f2758199-fa64-4a19-d0bb-ce26f516c1fa"
      },
      "outputs": [],
      "source": [
        "# One-hot encode categorical variables\n",
        "# Select only categorical columns\n",
        "categorical_cols = datan.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Limit to important categorical features to avoid too many dummy variables\n",
        "important_categoricals = ['Neighborhood', 'BldgType', 'HouseStyle', 'ExterQual', 'ExterCond',\n",
        "                          'Foundation', 'HeatingQC', 'CentralAir', 'KitchenQual',\n",
        "                          'GarageType', 'GarageFinish', 'PavedDrive', 'SaleCondition']\n",
        "\n",
        "# Keep only those that exist in our data\n",
        "categorical_to_encode = [col for col in important_categoricals if col in categorical_cols]\n",
        "\n",
        "# Create dummy variables\n",
        "datam = pd.get_dummies(datan, columns=categorical_to_encode, drop_first=True)\n",
        "\n",
        "print(f\"Shape after one-hot encoding: {datam.shape}\")\n",
        "print(f\"Encoded categorical columns: {categorical_to_encode}\")\n",
        "datam.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "tt02nSd0nER_",
        "outputId": "c482371a-6fbf-4710-f5fe-26174c44dd14"
      },
      "outputs": [],
      "source": [
        "datam.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "IBGIrwr0niwj",
        "outputId": "3060d3d5-c477-4dbf-cf81-2263cb04a6d5"
      },
      "outputs": [],
      "source": [
        "# Using LabelEncoder to transform remaining categorical variables to numeric variables\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Separate features and target\n",
        "X = datam.drop(columns=['SalePrice', 'SalePrice_log'], axis=1)\n",
        "y = datam['SalePrice']\n",
        "\n",
        "# Find remaining categorical columns (those not one-hot encoded)\n",
        "cat_f = X.select_dtypes(include='object').columns\n",
        "print(f\"Remaining categorical columns to encode: {list(cat_f)}\")\n",
        "\n",
        "# Encode remaining categorical features\n",
        "X_encoded = X.copy()\n",
        "label_encoders = {}\n",
        "for col in cat_f:\n",
        "    le = LabelEncoder()\n",
        "    X_encoded[col] = le.fit_transform(X_encoded[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(f\"\\nFinal feature shape: {X_encoded.shape}\")\n",
        "print(f\"Target variable shape: {y.shape}\")\n",
        "X_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-cuuordoCFb",
        "outputId": "00baff04-cf09-4a27-ee5e-e78872fa3597"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
        "\n",
        "# Calculate mutual information scores for all features\n",
        "selector = SelectKBest(score_func=mutual_info_regression, k='all')\n",
        "selector.fit(X_encoded, y)\n",
        "\n",
        "mi_scores = pd.DataFrame({\n",
        "    'Feature': X_encoded.columns,\n",
        "    'MI Score': selector.scores_\n",
        "}).sort_values(by='MI Score', ascending=False)\n",
        "\n",
        "print(\"Top 20 Features by Mutual Information Score:\")\n",
        "print(mi_scores.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qGaGyDcN3FT",
        "outputId": "47937f0f-83b5-43f6-f90f-d8dc31ba6e49"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import f_regression\n",
        "\n",
        "# Apply f_regression\n",
        "f_selector = SelectKBest(score_func=f_regression, k='all')\n",
        "f_selector.fit(X_encoded, y)\n",
        "\n",
        "# Collect scores\n",
        "f_scores = pd.DataFrame({\n",
        "    'Feature': X_encoded.columns,\n",
        "    'F_Score': f_selector.scores_,\n",
        "    'p_value': f_selector.pvalues_\n",
        "}).sort_values(by='F_Score', ascending=False)\n",
        "\n",
        "print(\"Top 20 Features by F-Score (Linear Relation with SalePrice):\")\n",
        "print(f_scores.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xf3nSDFIJ18Q",
        "outputId": "20738010-4f24-48c2-8bb8-5729fedff1d7"
      },
      "outputs": [],
      "source": [
        "# Train Random Forest model to get feature importance\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_encoded, y)\n",
        "\n",
        "# Get feature importance\n",
        "importances = pd.Series(rf.feature_importances_, index=X_encoded.columns)\n",
        "top_features = importances.sort_values(ascending=False).head(30)\n",
        "\n",
        "print(\"Top 20 Features by Random Forest Importance:\")\n",
        "print(top_features)\n",
        "\n",
        "# Visualize top features\n",
        "plt.figure(figsize=(10, 8))\n",
        "top_features.plot(kind='barh')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Top 30 Most Important Features')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9sVwdxUtlEpw",
        "outputId": "5fb4c411-ce9e-422a-e46f-6e36cbcae1a7"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
        "import pandas as pd\n",
        "\n",
        "# --- Target choices ---\n",
        "targets = {\n",
        "    \"SalePrice\": datan[\"SalePrice\"],\n",
        "    \"SalePrice_log\": datan[\"SalePrice_log\"]\n",
        "}\n",
        "\n",
        "# --- Loop through both targets ---\n",
        "results = {}\n",
        "\n",
        "for name, y in targets.items():\n",
        "    f_selector = SelectKBest(score_func=f_regression, k='all')\n",
        "    f_selector.fit(X_encoded, y)\n",
        "\n",
        "    f_scores = pd.DataFrame({\n",
        "        'Feature': X_encoded.columns,\n",
        "        'F_Score': f_selector.scores_,\n",
        "        'p_value': f_selector.pvalues_\n",
        "    }).sort_values(by='F_Score', ascending=False)\n",
        "\n",
        "    mi_scores = pd.Series(mutual_info_regression(X_encoded, y, random_state=42),\n",
        "                          index=X_encoded.columns, name='MI_Score').sort_values(ascending=False)\n",
        "\n",
        "    results[name] = (f_scores, mi_scores)\n",
        "\n",
        "# --- Compare top 10 for both targets ---\n",
        "print(\"Top F-test features for SalePrice_log:\")\n",
        "display(results[\"SalePrice_log\"][0].head(10))\n",
        "\n",
        "print(\"Top Mutual Information features for SalePrice_log:\")\n",
        "display(results[\"SalePrice_log\"][1].head(10))\n",
        "\n",
        "print(\"Top F-test features for SalePrice (raw):\")\n",
        "display(results[\"SalePrice\"][0].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0dJufrSmm7k",
        "outputId": "2b9e1358-8a5f-4ba3-9c9e-ed47cb6387f3"
      },
      "outputs": [],
      "source": [
        "# --- Combine F-test and Mutual Information top 30 ---\n",
        "top_f = f_scores.head(30)['Feature'].tolist()\n",
        "top_mi = mi_scores.head(30).index.tolist()\n",
        "\n",
        "# Combine both sets (union)\n",
        "filter_top30 = list(set(top_f) | set(top_mi))\n",
        "print(f\"Total unique top features from filters: {len(filter_top30)}\")\n",
        "\n",
        "X_filter = X_encoded[filter_top30]\n",
        "y_log = datam['SalePrice_log']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8UsoSbb-NEm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "9JQd1ID9mtY9",
        "outputId": "cff10861-ec5a-4907-da3f-84b2b2b3ed1a"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "# --- Train-test split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_filter,  # from filter-based selection (top 30)\n",
        "    datan[\"SalePrice_log\"],  # target (use log version)\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- Random Forest Regressor ---\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# --- Cross-validation setup ---\n",
        "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# --- RFECV setup ---\n",
        "rfecv = RFECV(\n",
        "    estimator=rf,\n",
        "    step=1,         # remove one feature per iteration\n",
        "    cv=cv,\n",
        "    scoring=\"r2\",   # use RÂ² for scoring\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# --- Fit the selector ---\n",
        "rfecv.fit(X_train, y_train)\n",
        "\n",
        "# --- Get selected features ---\n",
        "selected_rfecv = X_filter.columns[rfecv.support_].tolist()\n",
        "print(f\"[RFECV] Optimal #features: {rfecv.n_features_}\")\n",
        "print(\"Selected features:\", selected_rfecv)\n",
        "\n",
        "# --- Evaluate performance on hold-out set ---\n",
        "rf.fit(X_train[selected_rfecv], y_train)\n",
        "pred = rf.predict(X_test[selected_rfecv])\n",
        "\n",
        "r2 = r2_score(y_test, pred)\n",
        "mae = mean_absolute_error(y_test, pred)\n",
        "print(f\"[RFECV] Hold-out RÂ²: {r2:.4f} | MAE: {mae:.3f}\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])\n",
        "plt.xlabel(\"Number of Features Selected\")\n",
        "plt.ylabel(\"Cross-Validated RÂ²\")\n",
        "plt.title(\"RFECV Feature Selection Performance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sxBB8gUOnFuR",
        "outputId": "279e3cd6-7a76-4389-f507-fe33d8d448ac"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Train-test split (reuse previous or recreate) ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_filter,              # top features from filter stage\n",
        "    datan[\"SalePrice_log\"],  # target\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- Build pipeline: scaling + Lasso with cross-validation ---\n",
        "lasso_pipe = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LassoCV(cv=5, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# --- Fit model ---\n",
        "lasso_pipe.fit(X_train, y_train)\n",
        "\n",
        "# --- Retrieve coefficients ---\n",
        "lasso = lasso_pipe.named_steps[\"lassocv\"]\n",
        "coef_series = pd.Series(lasso.coef_, index=X_filter.columns)\n",
        "\n",
        "# --- Non-zero coefficients (selected features) ---\n",
        "lasso_selected = coef_series[coef_series != 0].sort_values(key=abs, ascending=False)\n",
        "print(f\"[LASSO] Selected {len(lasso_selected)} features\")\n",
        "display(lasso_selected.head(15))\n",
        "\n",
        "# --- Evaluate performance ---\n",
        "y_pred = lasso_pipe.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"[LASSO] Hold-out RÂ²: {r2:.4f} | MAE: {mae:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "lasso_selected.head(30).plot(kind=\"barh\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title(\"Top Lasso-Selected Features (Coefficient Magnitude)\")\n",
        "plt.xlabel(\"Coefficient (Absolute Value)\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfAIfc1V-Osj",
        "outputId": "54f6983d-46b9-4ed1-82e8-e6c8d164ea1d"
      },
      "outputs": [],
      "source": [
        "# --- Combine all unique features ---\n",
        "combined_features = set(filter_top30) | set(selected_rfecv) | set(lasso_selected.index)\n",
        "common_features = set(filter_top30) & set(selected_rfecv) & set(lasso_selected.index)\n",
        "\n",
        "print(f\"Total unique selected features: {len(combined_features)}\")\n",
        "print(f\"Highly consistent across all methods: {len(common_features)}\")\n",
        "\n",
        "print(\"\\nCommon features across ALL methods:\")\n",
        "print(list(common_features))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya7_JEjTEUnB",
        "outputId": "d19a6b00-cd6f-4158-c626-1ab786c70343"
      },
      "outputs": [],
      "source": [
        "X_final = X_encoded[list(combined_features)]\n",
        "y_final = datan[\"SalePrice_log\"]\n",
        "\n",
        "print(\"Final dataset shape:\", X_final.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "qiDdcNij-Stv",
        "outputId": "52dfbfbf-f74a-4bc4-b089-e58b794c14be"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- Scale the data ---\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_final)\n",
        "\n",
        "# --- Apply PCA ---\n",
        "pca = PCA(n_components=None, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# --- Explained variance ratio ---\n",
        "explained_var = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "# --- Plot how much variance is explained ---\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(range(1, len(explained_var)+1), explained_var, marker='o')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('PCA Variance Explained by Components')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvK-k5aIEf-x",
        "outputId": "d8b4cd82-2f05-4088-deef-a8288164f442"
      },
      "outputs": [],
      "source": [
        "n_components_95 = np.argmax(explained_var >= 0.95) + 1\n",
        "print(f\"Number of components to retain 95% variance: {n_components_95}\")\n",
        "# Reducing data\n",
        "pca_final = PCA(n_components=n_components_95, random_state=42)\n",
        "X_reduced = pca_final.fit_transform(X_scaled)\n",
        "\n",
        "print(\"Reduced shape:\", X_reduced.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS48tKkqEs0w",
        "outputId": "82eac320-655b-4707-d461-b13d9f30871e"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_reduced, y_final, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "pred = rf.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, pred)\n",
        "mae = mean_absolute_error(y_test, pred)\n",
        "print(f\"[PCA Reduced Model] RÂ²: {r2:.4f} | MAE: {mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **STEP 8: MODEL CONSTRUCTION**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for model construction\n",
        "# Use the final selected features (X_final) and log-transformed target (y_final)\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
        "    X_final, y_final, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Also get the original SalePrice for interpretation\n",
        "y_train_orig = datan.loc[X_train.index, 'SalePrice']\n",
        "y_test_orig = datan.loc[X_test.index, 'SalePrice']\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"\\nTraining target (log) range: {y_train_log.min():.2f} to {y_train_log.max():.2f}\")\n",
        "print(f\"Test target (log) range: {y_test_log.min():.2f} to {y_test_log.max():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.1 Simple Linear Regression\n",
        "\n",
        "Build a simple linear regression model using the single most important feature (OverallQual based on feature selection results).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Select the most important single feature (OverallQual)\n",
        "# Based on feature selection, OverallQual is one of the top features\n",
        "single_feature = 'OverallQual'\n",
        "X_train_simple = X_train[[single_feature]]\n",
        "X_test_simple = X_test[[single_feature]]\n",
        "\n",
        "# Build Simple Linear Regression model\n",
        "simple_lr = LinearRegression()\n",
        "simple_lr.fit(X_train_simple, y_train_log)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_simple_log = simple_lr.predict(X_test_simple)\n",
        "\n",
        "# Convert predictions back to original scale (inverse log transform)\n",
        "y_pred_simple = np.expm1(y_pred_simple_log)\n",
        "\n",
        "print(\"Simple Linear Regression Model\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Feature used: {single_feature}\")\n",
        "print(f\"Coefficient: {simple_lr.coef_[0]:.4f}\")\n",
        "print(f\"Intercept: {simple_lr.intercept_:.4f}\")\n",
        "print(f\"\\nModel equation: log(SalePrice) = {simple_lr.intercept_:.4f} + {simple_lr.coef_[0]:.4f} * {single_feature}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.2 Multiple Linear Regression\n",
        "\n",
        "Build a multiple linear regression model using top selected features from feature selection phase.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build Multiple Linear Regression model using all selected features\n",
        "# Scale features for better model performance\n",
        "scaler_mlr = StandardScaler()\n",
        "X_train_scaled = scaler_mlr.fit_transform(X_train)\n",
        "X_test_scaled = scaler_mlr.transform(X_test)\n",
        "\n",
        "# Build Multiple Linear Regression model\n",
        "multiple_lr = LinearRegression()\n",
        "multiple_lr.fit(X_train_scaled, y_train_log)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_multiple_log = multiple_lr.predict(X_test_scaled)\n",
        "\n",
        "# Convert predictions back to original scale (inverse log transform)\n",
        "y_pred_multiple = np.expm1(y_pred_multiple_log)\n",
        "\n",
        "print(\"Multiple Linear Regression Model\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Number of features used: {len(X_train.columns)}\")\n",
        "print(f\"Intercept: {multiple_lr.intercept_:.4f}\")\n",
        "print(f\"\\nTop 10 feature coefficients:\")\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': multiple_lr.coef_\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(coef_df.head(10).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **STEP 9: MODEL EVALUATION**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    \"\"\"Calculate RMSE, MAE, and RÂ² metrics\"\"\"\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n{model_name} Evaluation Metrics\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"RMSE (Root Mean Squared Error): ${rmse:,.2f}\")\n",
        "    print(f\"MAE (Mean Absolute Error): ${mae:,.2f}\")\n",
        "    print(f\"RÂ² (Coefficient of Determination): {r2:.4f}\")\n",
        "    print(f\"\\nInterpretation:\")\n",
        "    print(f\"- RMSE: On average, predictions are off by ${rmse:,.2f}\")\n",
        "    print(f\"- MAE: The average absolute error is ${mae:,.2f}\")\n",
        "    print(f\"- RÂ²: The model explains {r2*100:.2f}% of the variance in SalePrice\")\n",
        "\n",
        "    return {'RMSE': rmse, 'MAE': mae, 'RÂ²': r2}\n",
        "\n",
        "# Evaluate Simple Linear Regression\n",
        "metrics_simple = evaluate_model(y_test_orig, y_pred_simple, \"Simple Linear Regression\")\n",
        "\n",
        "# Evaluate Multiple Linear Regression\n",
        "metrics_multiple = evaluate_model(y_test_orig, y_pred_multiple, \"Multiple Linear Regression\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare models side by side\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['Simple Linear Regression', 'Multiple Linear Regression'],\n",
        "    'RMSE': [metrics_simple['RMSE'], metrics_multiple['RMSE']],\n",
        "    'MAE': [metrics_simple['MAE'], metrics_multiple['MAE']],\n",
        "    'RÂ²': [metrics_simple['RÂ²'], metrics_multiple['RÂ²']]\n",
        "})\n",
        "\n",
        "print(\"\\nModel Comparison Summary\")\n",
        "print(\"=\" * 70)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Determine best model\n",
        "best_model_idx = comparison_df['RÂ²'].idxmax()\n",
        "best_model = comparison_df.loc[best_model_idx, 'Model']\n",
        "print(f\"\\nBest Model: {best_model} (Highest RÂ²: {comparison_df.loc[best_model_idx, 'RÂ²']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Interpretation\n",
        "\n",
        "### Simple Linear Regression Interpretation\n",
        "- The coefficient shows how much log(SalePrice) changes per unit change in OverallQual\n",
        "- A positive coefficient indicates that higher quality ratings lead to higher prices\n",
        "\n",
        "### Multiple Linear Regression Interpretation\n",
        "- Each coefficient represents the contribution of that feature to the predicted log(SalePrice)\n",
        "- Features with larger absolute coefficients have more influence on the prediction\n",
        "- Positive coefficients indicate positive correlation with price, negative coefficients indicate negative correlation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **STEP 10: VISUALIZATION & STORYTELLING**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set style for better-looking plots\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8-darkgrid')\n",
        "except:\n",
        "    try:\n",
        "        plt.style.use('seaborn-darkgrid')\n",
        "    except:\n",
        "        plt.style.use('ggplot')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create a comprehensive visualization dashboard\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "# 1. Predicted vs Actual Scatter Plot (Simple Linear Regression)\n",
        "ax1 = plt.subplot(3, 3, 1)\n",
        "plt.scatter(y_test_orig, y_pred_simple, alpha=0.6, color='steelblue')\n",
        "plt.plot([y_test_orig.min(), y_test_orig.max()],\n",
        "         [y_test_orig.min(), y_test_orig.max()], 'r--', lw=2, label='Perfect Prediction')\n",
        "plt.xlabel('Actual SalePrice ($)')\n",
        "plt.ylabel('Predicted SalePrice ($)')\n",
        "plt.title(f'Simple LR: Predicted vs Actual\\nRÂ² = {metrics_simple[\"RÂ²\"]:.4f}, RMSE = ${metrics_simple[\"RMSE\"]:,.0f}')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Predicted vs Actual Scatter Plot (Multiple Linear Regression)\n",
        "ax2 = plt.subplot(3, 3, 2)\n",
        "plt.scatter(y_test_orig, y_pred_multiple, alpha=0.6, color='coral')\n",
        "plt.plot([y_test_orig.min(), y_test_orig.max()],\n",
        "         [y_test_orig.min(), y_test_orig.max()], 'r--', lw=2, label='Perfect Prediction')\n",
        "plt.xlabel('Actual SalePrice ($)')\n",
        "plt.ylabel('Predicted SalePrice ($)')\n",
        "plt.title(f'Multiple LR: Predicted vs Actual\\nRÂ² = {metrics_multiple[\"RÂ²\"]:.4f}, RMSE = ${metrics_multiple[\"RMSE\"]:,.0f}')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Residual Plot (Simple Linear Regression)\n",
        "ax3 = plt.subplot(3, 3, 3)\n",
        "residuals_simple = y_test_orig - y_pred_simple\n",
        "plt.scatter(y_pred_simple, residuals_simple, alpha=0.6, color='steelblue')\n",
        "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "plt.xlabel('Predicted SalePrice ($)')\n",
        "plt.ylabel('Residuals ($)')\n",
        "plt.title('Simple LR: Residual Plot')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Residual Plot (Multiple Linear Regression)\n",
        "ax4 = plt.subplot(3, 3, 4)\n",
        "residuals_multiple = y_test_orig - y_pred_multiple\n",
        "plt.scatter(y_pred_multiple, residuals_multiple, alpha=0.6, color='coral')\n",
        "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "plt.xlabel('Predicted SalePrice ($)')\n",
        "plt.ylabel('Residuals ($)')\n",
        "plt.title('Multiple LR: Residual Plot')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Feature Importance (Top 10 coefficients from Multiple LR)\n",
        "ax5 = plt.subplot(3, 3, 5)\n",
        "top_features = coef_df.head(10)\n",
        "colors = ['green' if x > 0 else 'red' for x in top_features['Coefficient']]\n",
        "plt.barh(range(len(top_features)), top_features['Coefficient'], color=colors)\n",
        "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.title('Top 10 Feature Coefficients\\n(Multiple Linear Regression)')\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 6. Distribution of Residuals (Simple LR)\n",
        "ax6 = plt.subplot(3, 3, 6)\n",
        "plt.hist(residuals_simple, bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "plt.xlabel('Residuals ($)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Simple LR: Distribution of Residuals')\n",
        "plt.axvline(x=0, color='r', linestyle='--', lw=2)\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 7. Distribution of Residuals (Multiple LR)\n",
        "ax7 = plt.subplot(3, 3, 7)\n",
        "plt.hist(residuals_multiple, bins=30, color='coral', alpha=0.7, edgecolor='black')\n",
        "plt.xlabel('Residuals ($)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Multiple LR: Distribution of Residuals')\n",
        "plt.axvline(x=0, color='r', linestyle='--', lw=2)\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 8. Model Comparison Bar Chart\n",
        "ax8 = plt.subplot(3, 3, 8)\n",
        "metrics_to_plot = ['RMSE', 'MAE']\n",
        "x_pos = np.arange(len(metrics_to_plot))\n",
        "width = 0.35\n",
        "plt.bar(x_pos - width/2, [metrics_simple[m] for m in metrics_to_plot],\n",
        "        width, label='Simple LR', color='steelblue', alpha=0.8)\n",
        "plt.bar(x_pos + width/2, [metrics_multiple[m] for m in metrics_to_plot],\n",
        "        width, label='Multiple LR', color='coral', alpha=0.8)\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Error ($)')\n",
        "plt.title('Model Comparison: RMSE and MAE')\n",
        "plt.xticks(x_pos, metrics_to_plot)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 9. RÂ² Comparison\n",
        "ax9 = plt.subplot(3, 3, 9)\n",
        "models = ['Simple LR', 'Multiple LR']\n",
        "r2_scores = [metrics_simple['RÂ²'], metrics_multiple['RÂ²']]\n",
        "colors_bar = ['steelblue', 'coral']\n",
        "bars = plt.bar(models, r2_scores, color=colors_bar, alpha=0.8, edgecolor='black')\n",
        "plt.ylabel('RÂ² Score')\n",
        "plt.title('Model Comparison: RÂ² Score')\n",
        "plt.ylim([0, 1])\n",
        "for i, (bar, score) in enumerate(zip(bars, r2_scores)):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{score:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additional segmented visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Price by Overall Quality (from original data)\n",
        "ax1 = axes[0, 0]\n",
        "quality_price = datan.groupby('OverallQual')['SalePrice'].mean()\n",
        "ax1.bar(quality_price.index, quality_price.values, color='teal', alpha=0.7, edgecolor='black')\n",
        "ax1.set_xlabel('Overall Quality')\n",
        "ax1.set_ylabel('Average SalePrice ($)')\n",
        "ax1.set_title('Average Sale Price by Overall Quality')\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 2. Price by Number of Bedrooms\n",
        "ax2 = axes[0, 1]\n",
        "bedroom_price = datan.groupby('BedroomAbvGr')['SalePrice'].mean()\n",
        "ax2.bar(bedroom_price.index, bedroom_price.values, color='purple', alpha=0.7, edgecolor='black')\n",
        "ax2.set_xlabel('Number of Bedrooms')\n",
        "ax2.set_ylabel('Average SalePrice ($)')\n",
        "ax2.set_title('Average Sale Price by Number of Bedrooms')\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 3. Price by Building Type\n",
        "ax3 = axes[1, 0]\n",
        "bldgtype_price = datan.groupby('BldgType')['SalePrice'].mean().sort_values()\n",
        "ax3.barh(range(len(bldgtype_price)), bldgtype_price.values, color='orange', alpha=0.7, edgecolor='black')\n",
        "ax3.set_yticks(range(len(bldgtype_price)))\n",
        "ax3.set_yticklabels(bldgtype_price.index)\n",
        "ax3.set_xlabel('Average SalePrice ($)')\n",
        "ax3.set_title('Average Sale Price by Building Type')\n",
        "ax3.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 4. Price Distribution by Neighborhood (Top 10)\n",
        "ax4 = axes[1, 1]\n",
        "neighborhood_price = datan.groupby('Neighborhood')['SalePrice'].mean().sort_values(ascending=False).head(10)\n",
        "ax4.barh(range(len(neighborhood_price)), neighborhood_price.values, color='crimson', alpha=0.7, edgecolor='black')\n",
        "ax4.set_yticks(range(len(neighborhood_price)))\n",
        "ax4.set_yticklabels(neighborhood_price.index)\n",
        "ax4.set_xlabel('Average SalePrice ($)')\n",
        "ax4.set_title('Top 10 Neighborhoods by Average Sale Price')\n",
        "ax4.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Key Metrics Summary\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"KEY METRICS SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n### Model Performance Metrics\\n\")\n",
        "\n",
        "print(\"**Simple Linear Regression:**\")\n",
        "print(f\"- **RMSE**: ${metrics_simple['RMSE']:,.2f} - On average, predictions deviate by this amount\")\n",
        "print(f\"- **MAE**: ${metrics_simple['MAE']:,.2f} - The average absolute prediction error\")\n",
        "print(f\"- **RÂ²**: {metrics_simple['RÂ²']:.4f} - The model explains {metrics_simple['RÂ²']*100:.2f}% of price variance\")\n",
        "\n",
        "print(\"\\n**Multiple Linear Regression:**\")\n",
        "print(f\"- **RMSE**: ${metrics_multiple['RMSE']:,.2f} - On average, predictions deviate by this amount\")\n",
        "print(f\"- **MAE**: ${metrics_multiple['MAE']:,.2f} - The average absolute prediction error\")\n",
        "print(f\"- **RÂ²**: {metrics_multiple['RÂ²']:.4f} - The model explains {metrics_multiple['RÂ²']*100:.2f}% of price variance\")\n",
        "\n",
        "print(\"\\n### Key Insights\\n\")\n",
        "\n",
        "print(\"1. **Model Performance**: The Multiple Linear Regression model performs better than Simple Linear Regression, achieving a higher RÂ² score and lower error metrics.\")\n",
        "\n",
        "print(\"\\n2. **Feature Importance**: OverallQual, TotalSF, GrLivArea, and GarageArea are among the most influential features in predicting house prices.\")\n",
        "\n",
        "mae_pct = (metrics_multiple['MAE'] / datan['SalePrice'].mean()) * 100\n",
        "print(f\"\\n3. **Model Accuracy**: The best model (Multiple Linear Regression) can predict house prices with an average error of approximately ${metrics_multiple['MAE']:,.0f}, which represents about {mae_pct:.1f}% of the average house price.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary and Conclusions\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"SUMMARY AND CONCLUSIONS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n### Project Overview\")\n",
        "print(\"This project analyzed the Kaggle House Prices dataset to build regression models for predicting house sale prices.\")\n",
        "print(\"The analysis included comprehensive data preprocessing, feature engineering, and model evaluation.\")\n",
        "\n",
        "print(\"\\n### Key Findings\\n\")\n",
        "\n",
        "print(\"1. **Data Quality**: The dataset contained 1,460 houses with 81 features. After cleaning and feature engineering, we worked with 35 selected features.\")\n",
        "\n",
        "print(\"\\n2. **Feature Engineering**: Created meaningful features such as TotalSF, PropertyAge, QualityScore, and binary indicators (HasGarage, HasBasement, HasFireplace) that improved model performance.\")\n",
        "\n",
        "print(\"\\n3. **Model Performance**:\")\n",
        "print(f\"   - Simple Linear Regression using OverallQual achieved an RÂ² of {metrics_simple['RÂ²']:.4f}\")\n",
        "print(f\"   - Multiple Linear Regression using 35 features achieved an RÂ² of {metrics_multiple['RÂ²']:.4f}\")\n",
        "print(\"   - The Multiple Linear Regression model provides better predictive accuracy\")\n",
        "\n",
        "print(\"\\n4. **Key Predictors**: OverallQual, TotalSF, GrLivArea, and GarageArea are the strongest predictors of house prices.\")\n",
        "\n",
        "print(\"\\n### Next Steps\\n\")\n",
        "\n",
        "print(\"1. **Model Improvements**:\")\n",
        "print(\"   - Try more advanced models (Random Forest, Gradient Boosting, XGBoost)\")\n",
        "print(\"   - Implement hyperparameter tuning\")\n",
        "print(\"   - Use ensemble methods to combine multiple models\")\n",
        "\n",
        "print(\"\\n2. **Feature Engineering**:\")\n",
        "print(\"   - Explore interaction features between important variables\")\n",
        "print(\"   - Consider polynomial features for non-linear relationships\")\n",
        "print(\"   - Investigate temporal features more deeply\")\n",
        "\n",
        "print(\"\\n3. **Model Validation**:\")\n",
        "print(\"   - Implement k-fold cross-validation for more robust evaluation\")\n",
        "print(\"   - Test on external validation set\")\n",
        "print(\"   - Analyze prediction errors for specific property types or neighborhoods\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
