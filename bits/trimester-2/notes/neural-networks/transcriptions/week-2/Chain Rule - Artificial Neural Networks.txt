Hello everyone. Welcome back to module 2 of artificial neural networks. In this video, we will refresh our concept of chain rule. By the end of this video, you will understand why the chain rule is essential for composite functions. You will be able to apply the chain rule to compute derivatives through intermediate variables.
You will compute sensitivities with respect to inputs and parameters. And finally, you will recognize the chain rule as the mathematical backbone of deep neural networks.
First of all, why do we need the chain rule? Many real-world systems are not described by a single simple equation. Instead, they are constructed as compositions of simpler functions.
In such systems, the output usually depends on intermediate variables and those intermediate variables depend on the input. This means the effect of the input on the output is indirect.
If we want to compute sensitivities correctly in such systems, we must use the chain rule. Neural networks are exactly of this form. They are deep compositions of many simple functions.
So, before we ever study neural networks training, we must first master the chain rule. Let us start with the simplest possible composite function. We define u = 3x and y = u^2. This can also be written as y = f . Here, x affects u and u affects y. Therefore, the effect of x on y is equal to f . Here, x affects u and u affects y. Therefore, the effect of x on y is equal to f . Here, x affects u and u affects y.
Therefore, x affects u. Therefore, x affects u. Therefore, x affects u. Therefore, the effect of x is equal to f . Here, x affects u. This is exactly the kind of structure for which the chain rule was invented.
We will be able to compute how y changes with respect to x. We cannot differentiate y directly with respect to x because y does not depend on x directly. Instead, we apply the chain rule which states that
x is equal to x is equal to x. This tells us that the sensitivity flows from y to u and then from u to x. Now, let us move to a slightly more realistic composite function that looks like a two-layer system.
We define u equals w1x plus d1 and y equals u square. We define u equals w1x plus d1 and y equals u square.
Here, x is the input w1 and w1 and w1 and w1 and w1 is the input. This tells us that the sensitivity flows from y to u and then from u to x. This tells us that the sensitivity flows from y to u and then from u to x.
Now, let us move to u to x. Now, let us move to a slightly more realistic composite function that looks like a two-layer system. We define u equals w1x plus d1 and y equals u square. Here, x is the input, w1 and b1 are the parameters, u is an intermediate variable and y is the final output.
Again, the key point is that y depends on everything only through u. So, any sensitivity of y with respect to any variable must flow through this intermediate variables. In this system, we are interested in understanding three specific sensitivities. How does x impact y, which is given by dy by dx? How does w1 impacts y, which is given by dy by dx?
How does w1 impacts y, which is given by dy by dw1? And how does b1 impact y, which is given by dy by db1? Since none of these variables affect y directly, every one of these derivatives must be computed using the chain rule through u. Now, let's try to find out dy by dx by applying y.
dy by dx by applying the chain rule. So, dy by dx is given by dy by du times du by dx. First, let's see the value of du by dx. Here, u is w1x plus b1. So, du by dx would be w1 plus, since b1 is constant,
So, it would become 0. So, it would become 0. So, it is w1. Similarly, dy by du is the derivative of u square with respect to u, which is given by 2u. So, dy by dx becomes dy by du, which is 2u times w1. Now, let's try to apply chain rule to w1. Maybe, you can take a pause and try to do this.
You can take a pause and try to do it yourself first. In this case, dy by dw1 is again given by dy by du times du by dw1.
dy by dw1 would be w1x plus d1. So, if we differentiate this with respect to w1, the output would be x plus 0, which is x. And dy by du, as we have seen earlier, is 2u. So, dy by dw1 is the product of 2u times x.
Next, we apply the chain rule to b1. Again, dy by d1, db1 is given by dy by du times du by db1.
dy by db1 equals w1 and x are constant with respect to b1. So, the value is going to be 0 plus derivative of b1 with respect to b1 is 1. So, the value is 1 here. And dy by du is given by 2u. So, dy by db1 becomes 2u.
dy by db1. So, this completes the chain rule. Now, let us summarize the main points of this video. Most real systems are built as functions of functions and this is exactly the situation for which the chain rule is needed.
In a two-layer composite function, every derivative of the output must pass through the intermediate variable. As a result, each total derivative becomes a product of local derivatives. This exact same mechanism extends naturally to much deeper systems, which is why the chain rule is the mathematical backbone of all multi-layer models. Thank you.
Thank you.
Thank you.
